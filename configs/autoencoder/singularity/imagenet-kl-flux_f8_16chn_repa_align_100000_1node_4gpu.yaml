model:
  base_learning_rate: 4.5e-6
  target: sgm.models.autoencoder.AutoencodingEngineWithAlignment
  params:
    input_key: image
    monitor: val/loss/rec
    disc_start_iter: 0
    ckpt_path: /guangtingsc_v-yuqianhong/ViT-VAE/pretrained_models/flux_vae.safetensors

    encoder_config:
      target: sgm.modules.diffusionmodules.model.Encoder
      params:
        attn_type: vanilla-xformers
        double_z: true
        z_channels: 16
        resolution: 256
        in_channels: 3
        out_ch: 3
        ch: 128
        ch_mult: [1, 2, 4, 4]
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0

    decoder_config:
      target: sgm.modules.diffusionmodules.model.Decoder
      params: ${model.params.encoder_config.params}
    
    vision_encoder_config:
      target: sgm.modules.vision_encoders.modules.FrozenCLIPImageEmbedder
      params:
        layer: last
    
    projector_config:
      target: sgm.modules.vision_encoders.VisionProjector
      params:
        image_size: 32
        patch_length: 256
        in_features: 16
        hidden_features: 1024
        out_features: 1024
        select_features: 16
    
    align_loss_config:
      target: sgm.modules.autoencoding.losses.align_loss.AlignLoss
      params:
        align_weight: 100000.0

    regularizer_config:
      target: sgm.modules.autoencoding.regularizers.DiagonalGaussianRegularizer

    loss_config:
      target: sgm.modules.autoencoding.losses.GeneralLPIPSWithDiscriminator
      params:
        perceptual_weight: 0.25
        disc_start: 20001
        disc_weight: 0.5
        learn_logvar: True

        regularization_weights:
          kl_loss: 1.0

data:
  target: sgm.data.imagenet.ImageNetLoader
  params:
    batch_size: 8
    num_workers: 1
    shuffle: False
    data_root: /guangtingsc_v-yuqianhong/ViT-VAE/ImageNet/ILSVRC2012/train
    image_size: 256


lightning:
  strategy:
    target: pytorch_lightning.strategies.DDPStrategy
    params:
      find_unused_parameters: True

  modelcheckpoint:
    params:
      every_n_train_steps: 5000

  callbacks:
    metrics_over_trainsteps_checkpoint:
      params:
        every_n_train_steps: 50000

    image_logger:
      target: main.ImageLogger
      params:
        enable_autocast: False
        batch_frequency: 1000
        max_images: 8
        increase_log_steps: True

  trainer:
    devices: 0, 1, 2, 3
    limit_val_batches: 50
    benchmark: True
    accumulate_grad_batches: 1
    val_check_interval: 10000
